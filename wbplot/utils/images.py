"""Auxiliary functions pertaining to the manipulation of neuroimaging files. """

import numpy as np
import nibabel as nib
from numpy import ndarray
from .. import constants, config
from . import plots
from os import system, remove, rename
from os.path import join
import xml.etree.cElementTree as eT
from matplotlib import colors as clrs
from matplotlib import cm

# Comment the line below to unsuppress console statements generated by nibabel
nib.imageglobals.logger.disabled = True


# def map_parcels_to_dlabels():
#     """
#
#     Returns
#     -------
#
#     """
#     out = dict.fromkeys(range(360))  # assuming Glasser parcellation
#     of = nib.load(config.PARCELLATION_FILE)
#     dlabels = extract_nifti_data(of)
#     for i in range(360):
#         out[i] = np.where(dlabels == i+1)[0]
#     return out


def map_unilateral_to_bilateral(pscalars, hemisphere):
    """
    Map 180 unilateral pscalars to 360 bilateral pscalars, padding contralateral
    hemisphere with zeros.

    Parameters
    ----------
    pscalars : numpy.ndarray
        unilateral parcellated scalars
    hemisphere : 'left' or 'right' or None

    Returns
    -------
    numpy.ndarray

    """
    hemisphere = check_hemisphere(pscalars=pscalars, hemisphere=hemisphere)
    if hemisphere is None:
        return pscalars
    pscalars_lr = np.zeros(360)
    if hemisphere == 'right':
        pscalars_lr[:180] = pscalars
    elif hemisphere == 'left':
        pscalars_lr[180:] = pscalars
    return pscalars_lr


def check_pscalars_unilateral(pscalars):
    """
    Check that unilateral pscalars have the expected size and shape.

    Parameters
    ----------
    pscalars : numpy.ndarray
        parcellated scalars

    Returns
    -------
    None

    """
    if type(pscalars) is not ndarray:
        raise RuntimeError("pscalars must be a NumPy array")
    if pscalars.ndim != 1:
        raise RuntimeError("pscalars must be one-dimensional")
    if pscalars.size != 180:
        raise RuntimeError("unilateral pscalars must be length 180")


def check_pscalars_bilateral(pscalars):
    """
    Check that bilateral pscalars have the expected size and shape.

    Parameters
    ----------
    pscalars : numpy.ndarray
        parcellated scalars

    Returns
    -------
    None

    """
    if type(pscalars) is not ndarray:
        raise RuntimeError("pscalars must be a NumPy array")
    if pscalars.ndim != 1:
        raise RuntimeError("pscalars must be one-dimensional")
    if pscalars.size != 360:
        raise RuntimeError("bilateral pscalars must be length 360")


def check_dscalars(dscalars):
    """
    Check that dscalars have the expected size and shape.
    TODO: expand to unilateral/bilateral

    Parameters
    ----------
    dscalars : numpy.ndarray
        dense scalars

    Returns
    -------
    None

    """
    if type(dscalars) is not ndarray:
        raise RuntimeError("dscalars must be a NumPy array")
    if dscalars.ndim != 1:
        raise RuntimeError("dscalars must be one-dimensional")
    if dscalars.size != 91282:
        raise RuntimeError("bilateral dscalars must be length 91282")


def check_hemisphere(pscalars, hemisphere):
    """
    Check hemisphere argument for package compatibility.

    Parameters
    ----------
    pscalars : numpy.ndarray
        parcels' scalar quantities
    hemisphere : 'left' or 'right' or None
        if bilateral, use None

    Returns
    -------
    'left' or 'right' or None

    """
    if pscalars.size != 360 and hemisphere is None:
        raise RuntimeError(
            "you must indicate which hemisphere these pscalars correspond to")
    options = ['left', 'l', 'L', 'right', 'r', 'R', None, 'lr', 'LR']
    if hemisphere not in options:
        raise ValueError("{} if not a valid hemisphere".format(hemisphere))
    if hemisphere in ['left', 'l', 'L']:
        return 'left'
    if hemisphere in ['right', 'r', 'R']:
        return 'right'
    if hemisphere in ['None', 'lr', 'LR']:
        return None


def extract_nifti_data(of):
    """Extract array of scalar quantities from a NIFTI2 image.

    Parameters
    ----------
    of : :class:`nibabel.Nifti2Image` instance
        the NIFTI2 image from which to extract scalar data

    Returns
    -------
    data : numpy.ndarray

    """
    return np.array(of.get_data()).squeeze()


def extract_gifti_data(of):
    """Extract array of scalar quantities from a GIFTI image.

    Parameters
    ----------
    of : :class:`nibabel.gifti.GiftiImage` instance
        the GIFTI image from which to extract scalar data

    Returns
    -------
    data : numpy.ndarray

    """
    return np.array(of.darrays[0].data).squeeze()


def write_parcellated_image(
        data, fout, hemisphere=None, cmap='magma', vrange=None):
    """
    Insert parcellated scalars into a pscalar file.

    Parameters
    ----------
    data : numpy.ndarray
        scalar map values
    fout : str
        absolute path to output neuroimaging file with *.dlabel.nii* extension
    hemisphere : 'left' or 'right' or None, default None
        which hemisphere `pscalars` correspond to. for bilateral data use None
    cmap : str
        a valid MATPLOTLIB colormap used to plot the data
    vrange : tuple
        data (min, max) for plotting; if None, use (min(data), max(data))

    Returns
    -------
    None

    Notes
    -----
    The file defined by wbplot.config.PARCELLATION_FILE is used as a template to
    achieve this. Thus the data provided to this function must be in the same
    parcellation as that file. By default, this is the HCP MMP1.0 parcellation;
    thus, `data` must be ordered as (R_1, R_2, ..., R_180, L_1, L_2, ..., L_180)
    if bilateral. If unilateral, they must be ordered from area V1 (parcel 1) to
    area p24 (parcel 180).
    """

    # Check provided inputs and pad contralateral hemisphere with 0 if necessary
    check_hemisphere(pscalars=data, hemisphere=hemisphere)
    cmap = plots.check_cmap_plt(cmap)
    pscalars_lr = map_unilateral_to_bilateral(
        pscalars=data, hemisphere=hemisphere)

    # Change the colors assigned to each parcel and save to `fout`
    c = Cifti()
    c.set_cmap(data=pscalars_lr, cmap=cmap, vrange=vrange)
    c.save(fout)


def write_dense_image(dscalars, fout, savedir=constants.DATA_DIR):

    """
    Insert dense scalars into a dscalar file.

    Parameters
    ----------
    dscalars : numpy.ndarray
        dense scalar data to write
    fout : str
        output filename. if an extension is provided, it must be .dscalar.nii
    savedir : str, default constants.DATA_DIR
        absolute path to directory in which to save the image. to use this
        function as part of the automated image-generating pipeline, it must be
        left as its default value

    Returns
    -------
    None

    """
    check_dscalars(dscalars)

    if fout[-12:] != ".dscalar.nii":
        fout += ".dscalar.nii"

    new_data = np.copy(dscalars)

    # Load template NIFTI file (from which to create a new file)
    of = nib.load(constants.DSCALAR_FILE)

    # Load data from the template file
    temp_data = np.array(of.get_data())

    # Reshape the new data appropriately
    data_to_write = new_data.reshape(np.shape(temp_data))

    # Create and save a new NIFTI2 image object
    new_img = nib.Nifti2Image(
        data_to_write, affine=of.affine, header=of.header)
    nib.save(new_img, join(savedir, fout))

    # # Change color palette and overwrite data in template file (which is loaded
    # # into the scene file for automated plotting)
    # change_palette(
    #     scalars=pscalars_lr, image=fout, cmap=cmap, palette_params=palette_params)


    # TODO: look over this and integrate as needed, moved from wbplot.dscalars()
    # new_data = np.copy(dscalars)
    #
    # # Load template NIFTI file (into which `dscalars` will be inserted)
    # of = nib.load(constants.DSCALAR_FILE)
    #
    # # Load data from the template file
    # temp_data = np.array(of.get_data())
    #
    # # # Overwrite existing template data with `dscalars`
    #
    # # First, write new data to existing template file
    # data_to_write = new_data.reshape(np.shape(temp_data))
    # new_img = nib.Nifti2Image(data_to_write, affine=of.affine, header=of.header)
    # prefix = constants.DSCALAR_FILE.split(".dscalar.nii")[0]
    # nib.save(new_img, constants.DSCALAR_FILE)
    #
    # # Use Workbench's command line utilities to change the color palette. Note
    # # that this command requires saving to a new CIFTI file, which I will do
    # # before overwriting the old file
    # cifti_out = prefix + "_temp.dscalar.nii"
    # cifti_in = constants.DSCALAR_FILE
    # cmd = "wb_command -cifti-palette %s %s %s -palette-name %s" % (
    #     cifti_in, "MODE_AUTO_SCALE_PERCENTAGE", cifti_out, cmap)
    # system(cmd)
    #
    # # Delete existing template file; rename new file to replace old template
    # remove(cifti_in)
    # rename(cifti_out, cifti_in)


def change_palette(scalars, image, cmap, palette_params=None):
    """
    TODO

    Parameters
    ----------
    scalars
    image
    cmap
    palette_params

    Returns
    -------

    """

    new_data = np.copy(scalars)

    # Load template dscalar file
    of = nib.load(constants.DSCALAR_FILE)
    temp_data = np.array(of.get_data())

    # Overwrite with new data
    data_to_write = new_data.reshape(np.shape(temp_data))
    new_img = nib.Nifti2Image(data_to_write, affine=of.affine, header=of.header)
    prefix = image.split(".")[0]
    nib.save(new_img, image)

    # Save new dscalar file if not overriding template
    if image != constants.DSCALAR_FILE:
        system("cp {} {}".format(constants.DSCALAR_FILE, image))

    # Use Workbench's command line utilities to change the color palette
    cifti_out = prefix + "_temp.dscalar.nii"
    cifti_in = image
    cmd = "wb_command -cifti-palette %s %s %s -palette-name %s" % (
        cifti_in, "MODE_AUTO_SCALE_PERCENTAGE", cifti_out, cmap)

    if palette_params:
        for k, v in palette_params.items():
            if hasattr(v, '__iter__'):
                if len(v) != 2:
                    raise RuntimeError(
                        "palette params must be a dict with values which are "
                        "either strings, numbers, or tuples")
                cmd += " -{} {} {}".format(k, v[0], v[1])
            else:
                cmd += " -{} {}".format(k, v)
    system(cmd)

    # Delete original file and rename file with modified color palette
    remove(cifti_in)
    rename(cifti_out, cifti_in)


class Cifti(object):
    """
    A class for changing the colors inside the metadata of a DLABEL neuroimaging
    file. Some of this code was contributed by Dr. Murat Demirtas while he was
    a post-doctoral researcher at Yale.
    """

    def __init__(self):

        of = nib.load(config.PARCELLATION_FILE)  # must be a DLABEL file!!
        self.data = of.get_data()
        self.affine = of.affine
        self.header = of.header
        self.extensions = eT.fromstring(self.header.extensions[0].get_content())
        self.vrange = None
        self.ischanged = False

    def set_cmap(self, data, cmap='magma', vrange=None, mappable=None):
        """
        Map scalar data to RGBA values and update file header metadata.

        Parameters
        ----------
        data : numpy.ndarray
            scalar data
        cmap : str or None, default 'magma'
            colormap to use for plotting
        vrange : tuple or None, default None
            data (min, max) for illustration; if None, use (min(data),max(data))
        mappable : Callable[float] or None, default None
            can be used to override arguments `cmap` and `vrange`, e.g. by
            specifying your own map from scalar input to RGBA output

        Returns
        -------
        None

        """
        if data.size != 360:
            raise RuntimeError(
                "pscalars must be length 360 for :class:~wbplot.images.Cifti")

        # Check input arguments
        cmap = plots.check_cmap_plt(cmap)
        self.vrange = (
            np.min(data), np.max(data)) if vrange is None else vrange
        self.vrange = plots.check_vrange(self.vrange)

        # Map scalar data to colors (R, G, B, Alpha)
        if mappable is None:
            cnorm = clrs.Normalize(vmin=self.vrange[0], vmax=self.vrange[1])
            clr_map = cm.ScalarMappable(cmap=cmap, norm=cnorm)
            colors = clr_map.to_rgba(data)
        else:
            colors = np.array([mappable(d) for d in data])

        # Update file header metadata
        for ii in range(1, len(self.extensions[0][1][0][1])):
            self.extensions[0][1][0][1][ii].set(
                'Red', str(colors[ii - 1, 0]))
            self.extensions[0][1][0][1][ii].set(
                'Green', str(colors[ii - 1, 1]))
            self.extensions[0][1][0][1][ii].set(
                'Blue', str(colors[ii - 1, 2]))
            self.extensions[0][1][0][1][ii].set(
                'Alpha', str(colors[ii - 1, 3]))
        self.ischanged = True

    # Write to class attribute self.header
    def write_extensions(self):
        self.header.extensions[0]._content = eT.tostring(self.extensions)

    def save(self, fout):
        """
        Write self.data to image `fout`.

        Parameters
        ----------
        fout : str
            absolute path to output neuroimaging file. must be a DLABEL file!!

        Returns
        -------
        None

        """
        if self.ischanged:
            self.write_extensions()
        new_img = nib.Nifti2Image(
            self.data, affine=self.affine, header=self.header)
        nib.save(new_img, fout)


# Pythonic version of this workbench command (primarily so I don't forget)
def cifti_parcellate(cifti_in, dlabel_in, cifti_out, direction='COLUMN'):
    cmd = "wb_command -cifti-parcellate {} {} {} {}".format(
        cifti_in, dlabel_in, direction, cifti_out)
    system(cmd)
