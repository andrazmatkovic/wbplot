import numpy as np
import nibabel as nib
from numpy import ndarray
from .. import constants, config
from . import plots
from os import system, remove, rename
from os.path import join
import xml.etree.cElementTree as eT
from matplotlib import colors as clrs
from matplotlib import cm

# Uncomment the line below to suppress console statements generated by nibabel
nib.imageglobals.logger.disabled = True


def extract_nifti_data(of):
    """Extract vector of scalar quantities from a NIFTI2 image.

    Parameters
    ----------
    of : Nifti2Image
        the NIFTI2 image from which to extract scalar data

    Returns
    -------
    data : ndarray
        scalar values in the input NIFTI2 image

    """
    return np.array(of.get_data()).squeeze()


def extract_gifti_data(of):
    """Extract vector of scalar quantities from a GIFTI image.

    Parameters
    ----------
    of : GiftiImage
        the GIFTI image from which to extract scalar data

    Returns
    -------
    data : ndarray
        scalar values in the input GIFTI image

    """
    return np.array(of.darrays[0].data).squeeze()


def write_parcellated_image(
        data, fout, hemisphere=None, cmap=None, vrange=None):
    """
    Insert parcellated scalars into a pscalar file.

    Parameters
    ----------
    data : numpy.ndarray
        scalar map values
    fout : str
        absolute path to neuroimaging file whose data will be overwritten
    hemisphere : 'left' or 'right' or None, default None
        which hemisphere `pscalars` correspond to. for bilateral data use None
    cmap : str
        color map
    vrange : TODO

    Returns
    -------
    None

    Notes
    -----
    This function assumes that the ordering of parcels... TODO

    """

    # Checks
    check_hemisphere(pscalars=data, hemisphere=hemisphere)
    cmap = plots.check_cmap(cmap)

    # Map from (possibly) unilateral to bilateral
    pscalars_lr = map_unilateral_to_bilateral(
        pscalars=data, hemisphere=hemisphere)

    # # Change color palette and overwrite data in template file (which is loaded
    # # into the scene file for automated plotting)
    # change_palette(
    #     scalars=pscalars_lr, image=fout, cmap=cmap, palette_params=palette_params)

    c = Cifti()
    c.set_cmap(data=pscalars_lr, cmap=cmap, vrange=vrange)
    c.save(fout=constants.DLABEL_FILE)


def map_parcels_to_dlabels():
    """
    TODO

    Returns
    -------

    """
    out = dict.fromkeys(range(360))  # assuming Glasser parcellation
    of = nib.load(config.PARCELLATION_FILE)
    dlabels = extract_nifti_data(of)
    for i in range(360):
        out[i] = np.where(dlabels == i+1)[0]
    return out


def map_unilateral_to_bilateral(pscalars, hemisphere):
    """

    Parameters
    ----------
    pscalars : numpy.ndarray
        unilateral parcellated scalars
    hemisphere : 'left' or 'right' or None

    Returns
    -------
    numpy.ndarray
        bilateral pscalars, with contralateral hemisphere padded with zeros

    """
    hemisphere = check_hemisphere(pscalars=pscalars, hemisphere=hemisphere)
    if hemisphere is None:
        return pscalars
    pscalars_lr = np.zeros(360)
    if hemisphere == 'right':
        pscalars_lr[:180] = pscalars
    elif hemisphere == 'left':
        pscalars_lr[180:] = pscalars
    return pscalars_lr


def check_hemisphere(pscalars, hemisphere):
    """
    Check hemisphere argument for package compatibility.

    Parameters
    ----------
    pscalars : TODO
    hemisphere : 'left' or 'right' or None

    Returns
    -------
    'left' or 'right' or None

    """
    if pscalars.size != 360 and hemisphere is None:
        raise RuntimeError(
            "you must indicate which hemisphere these pscalars correspond to")
    options = ['left', 'l', 'L', 'right', 'r', 'R', None, 'lr', 'LR']
    if hemisphere not in options:
        raise ValueError("{} if not a valid hemisphere".format(hemisphere))
    if hemisphere in ['left', 'l', 'L']:
        return 'left'
    if hemisphere in ['right', 'r', 'R']:
        return 'right'
    if hemisphere in ['None', 'lr', 'LR']:
        return None


def write_dense_image(dscalars, fout, savedir=constants.DATA_DIR):

    """
    Save dense scalars to a NIFTI neuroimaging file for visualization in
    Connectome Workbench.

    Parameters
    ----------
    dscalars : numpy.ndarray
        dense scalar data to write
    fout : str
        output filename. if an extension is provided, it must be .dscalar.nii
    savedir : str, default constants.DATA_DIR
        absolute path to directory in which to save the image. to use this
        function as part of the automated image-generating pipeline, it must be
        left as its default value

    Returns
    -------
    None

    """
    check_dscalars(dscalars)

    if fout[-12:] != ".dscalar.nii":
        fout += ".dscalar.nii"

    new_data = np.copy(dscalars)

    # Load template NIFTI file (from which to create a new file)
    of = nib.load(constants.DSCALAR_FILE)

    # Load data from the template file
    temp_data = np.array(of.get_data())

    # Reshape the new data appropriately
    data_to_write = new_data.reshape(np.shape(temp_data))

    # Create and save a new NIFTI2 image object
    new_img = nib.Nifti2Image(
        data_to_write, affine=of.affine, header=of.header)
    nib.save(new_img, join(savedir, fout))

    # TODO: look over this and integrate as needed, moved from wbplot.dscalars()
    # new_data = np.copy(dscalars)
    #
    # # Load template NIFTI file (into which `dscalars` will be inserted)
    # of = nib.load(constants.DSCALAR_FILE)
    #
    # # Load data from the template file
    # temp_data = np.array(of.get_data())
    #
    # # # Overwrite existing template data with `dscalars`
    #
    # # First, write new data to existing template file
    # data_to_write = new_data.reshape(np.shape(temp_data))
    # new_img = nib.Nifti2Image(data_to_write, affine=of.affine, header=of.header)
    # prefix = constants.DSCALAR_FILE.split(".dscalar.nii")[0]
    # nib.save(new_img, constants.DSCALAR_FILE)
    #
    # # Use Workbench's command line utilities to change the color palette. Note
    # # that this command requires saving to a new CIFTI file, which I will do
    # # before overwriting the old file
    # cifti_out = prefix + "_temp.dscalar.nii"
    # cifti_in = constants.DSCALAR_FILE
    # cmd = "wb_command -cifti-palette %s %s %s -palette-name %s" % (
    #     cifti_in, "MODE_AUTO_SCALE_PERCENTAGE", cifti_out, cmap)
    # system(cmd)
    #
    # # Delete existing template file; rename new file to replace old template
    # remove(cifti_in)
    # rename(cifti_out, cifti_in)


def change_palette(scalars, image, cmap, palette_params=None):
    """
    TODO

    Parameters
    ----------
    scalars
    image
    cmap
    palette_params

    Returns
    -------

    """

    # if scalars.size == 360:  # upsample to dense
    #     parcel2idx = map_parcels_to_dlabels()
    #     dscalars = np.zeros(91282)
    #     for i, x in enumerate(scalars):
    #         dscalars[parcel2idx[i]] = x
    #     scalars = dscalars

    new_data = np.copy(scalars)

    # Load template dscalar file
    of = nib.load(constants.DSCALAR_FILE)
    temp_data = np.array(of.get_data())

    # Overwrite with new data
    data_to_write = new_data.reshape(np.shape(temp_data))
    new_img = nib.Nifti2Image(data_to_write, affine=of.affine, header=of.header)
    prefix = image.split(".")[0]
    nib.save(new_img, image)

    # Save new dscalar file if not overriding template
    if image != constants.DSCALAR_FILE:
        system("cp {} {}".format(constants.DSCALAR_FILE, image))

    # Use Workbench's command line utilities to change the color palette
    cifti_out = prefix + "_temp.dscalar.nii"
    cifti_in = image
    cmd = "wb_command -cifti-palette %s %s %s -palette-name %s" % (
        cifti_in, "MODE_AUTO_SCALE_PERCENTAGE", cifti_out, cmap)

    if palette_params:
        for k, v in palette_params.items():
            if hasattr(v, '__iter__'):
                if len(v) != 2:
                    raise RuntimeError(
                        "palette params must be a dict with values which are "
                        "either strings, numbers, or tuples")
                cmd += " -{} {} {}".format(k, v[0], v[1])
            else:
                cmd += " -{} {}".format(k, v)
    print(cmd)
    system(cmd)

    # Delete original file and rename file with modified color palette
    remove(cifti_in)
    rename(cifti_out, cifti_in)
    print("color palette changed for {}".format(cifti_in))


# Pythonic version of this workbench command, primarily so I don't forget
def cifti_parcellate(cifti_in, dlabel_in, cifti_out, direction='COLUMN'):
    cmd = "wb_command -cifti-parcellate {} {} {} {}".format(
        cifti_in, dlabel_in, direction, cifti_out)
    system(cmd)


class Cifti(object):

    def __init__(self):

        of = nib.load(config.PARCELLATION_FILE)
        self.data = of.get_data()
        self.affine = of.affine
        self.header = of.header
        self.extensions = eT.fromstring(self.header.extensions[0].get_content())
        self.vrange = None
        self.ischanged = False

    def set_cmap(self, data, cmap=None, vrange=None, mappable=None):
        """
        Map scalar data to RGB values using the provided colormap.

        Parameters
        ----------
        data : numpy.ndarray
            scalar data
        cmap : str or None, default None
            colormap; if None, use DEFAULT_CMAP defined in wbplot.config
        vrange : tuple or None, default None
            data (min, max) for illustration
        mappable : Callable[float] or None, default None
            can be used to override arguments `cmap` and `vrange`, e.g. by
            specifying your own color mapping object

        Returns
        -------
        None

        """
        if data.size != 360:
            raise RuntimeError("pscalars must be length 360 for this class")

        cmap = plots.check_cmap(cmap)
        self.vrange = (
            np.min(data), np.max(data)) if vrange is None else vrange
        self.vrange = plots.check_vrange(self.vrange)

        # Map data to colors
        if mappable is None:
            cnorm = clrs.Normalize(vmin=self.vrange[0], vmax=self.vrange[1])
            # plt_cmap = cm.get_cmap(cmap)
            # plt_cmap.set_bad(color='grey', alpha=0)
            clr_map = cm.ScalarMappable(cmap=cmap, norm=cnorm)
            colors = clr_map.to_rgba(data)
        else:
            colors = np.array([mappable(d) for d in data])
        print(vrange, colors, data)
        for ii in range(1, len(self.extensions[0][1][0][1])):
            self.extensions[0][1][0][1][ii].set(
                'Red', str(colors[ii - 1, 0]))
            self.extensions[0][1][0][1][ii].set(
                'Green', str(colors[ii - 1, 1]))
            self.extensions[0][1][0][1][ii].set(
                'Blue', str(colors[ii - 1, 2]))
            self.extensions[0][1][0][1][ii].set(
                'Alpha', str(colors[ii - 1, 3]))
        self.ischanged = True

    def write_extensions(self):
        self.header.extensions[0]._content = eT.tostring(self.extensions)

    def save(self, fout):
        """

        Parameters
        ----------
        fout : str
            absolute path to output file

        Returns
        -------
        None

        """
        if self.ischanged:
            self.write_extensions()
        new_img = nib.Nifti2Image(
            self.data, affine=self.affine, header=self.header)
        nib.save(new_img, fout)


def check_pscalars_unilateral(pscalars):
    """

    Parameters
    ----------
    pscalars : array_like
        parcellated scalars

    Returns
    -------
    None

    """
    if type(pscalars) is not ndarray:
        raise RuntimeError("pscalars must be a NumPy array")
    if pscalars.ndim != 1:
        raise RuntimeError("pscalars must be one-dimensional")
    if pscalars.size != 180:
        raise RuntimeError("unilateral pscalars must be length 180")


def check_pscalars_bilateral(pscalars):
    """

    Parameters
    ----------
    pscalars : array_like
        parcellated scalars

    Returns
    -------
    None

    """
    if type(pscalars) is not ndarray:
        raise RuntimeError("pscalars must be a NumPy array")
    if pscalars.ndim != 1:
        raise RuntimeError("pscalars must be one-dimensional")
    if pscalars.size != 360:
        raise RuntimeError("bilateral pscalars must be length 360")


def check_dscalars(dscalars):
    """

    Parameters
    ----------
    dscalars : numpy.ndarray
        dense scalars

    Returns
    -------
    None

    """
    if type(dscalars) is not ndarray:
        raise RuntimeError("dscalars must be a NumPy array")
    if dscalars.ndim != 1:
        raise RuntimeError("dscalars must be one-dimensional")
    if dscalars.size != 91282:
        raise RuntimeError("bilateral dscalars must be length 91282")
